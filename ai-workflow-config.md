高速AI協調ワークフロー設定:

## 用途別モデル使い分け戦略

### 🚀 超高速 (1-2秒)
- **llama3.2:1b** - 簡単な質問、即答が必要なタスク

### ⚡ 高速 (3-6秒)  
- **llama3.2:3b** - 汎用タスク、コードレビュー
- **phi3.5:3.8b** - コード特化、プログラミング支援

### 🔍 特殊用途
- **all-minilm** - 軽量埋め込み処理
- **bge-large/mxbai-embed** - 高性能埋め込み

### ☁️ クラウド連携
- **Claude API** - 複雑な分析、長文生成のみ

約22GB → 5.2GB に削減完了！
